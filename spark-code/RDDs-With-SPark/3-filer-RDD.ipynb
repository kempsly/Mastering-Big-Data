{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/25 18:41:18 WARN Utils: Your hostname, Kempslys-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.57 instead (on interface en0)\n",
      "25/01/25 18:41:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/25 18:41:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"FilteringRDD\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 2 3 4 5',\n",
       " '6 7 8 9 10',\n",
       " '11 12 13 14 15',\n",
       " '16 17 18 19 20',\n",
       " '21 22 23 24 25',\n",
       " '26 27 28 29 30',\n",
       " '31 32 33 34 35',\n",
       " '36 37 38 39 40',\n",
       " '41 42 43 44 45',\n",
       " '46 47 48 49 50',\n",
       " '51 52 53 54 55',\n",
       " '56 57 58 59 60',\n",
       " '61 62 63 64 65',\n",
       " '66 67 68 69 70',\n",
       " '71 72 73 74 75',\n",
       " '76 77 78 79 80',\n",
       " '81 82 83 84 85',\n",
       " '86 87 88 89 90',\n",
       " '91 92 93 94 95',\n",
       " '96 97 98 99 100']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('sample_columned.txt')\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '100']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's fllat the rdd\n",
    "rdd_flatMapped = rdd.flatMap(lambda x: x.split(' '))\n",
    "rdd_flatMapped.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 11,\n",
       " 13,\n",
       " 15,\n",
       " 17,\n",
       " 19,\n",
       " 21,\n",
       " 23,\n",
       " 25,\n",
       " 27,\n",
       " 29,\n",
       " 31,\n",
       " 33,\n",
       " 35,\n",
       " 37,\n",
       " 39,\n",
       " 41,\n",
       " 43,\n",
       " 45,\n",
       " 47,\n",
       " 49,\n",
       " 51,\n",
       " 53,\n",
       " 55,\n",
       " 57,\n",
       " 59,\n",
       " 61,\n",
       " 63,\n",
       " 65,\n",
       " 67,\n",
       " 69,\n",
       " 71,\n",
       " 73,\n",
       " 75,\n",
       " 77,\n",
       " 79,\n",
       " 81,\n",
       " 83,\n",
       " 85,\n",
       " 87,\n",
       " 89,\n",
       " 91,\n",
       " 93,\n",
       " 95,\n",
       " 97,\n",
       " 99]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_filtered = rdd_flatMapped.map(lambda x: int(x)).filter(lambda x: x%2 != 0)\n",
    "rdd_filtered.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removeing words strting by a or c from the rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removeing words strting by a or c from the rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/25 19:55:46 WARN Utils: Your hostname, Kempslys-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.57 instead (on interface en0)\n",
      "25/01/25 19:55:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/25 19:55:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setAppName('WordsRemoving')\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this mango company animal',\n",
       " 'cat dog ant mic laptop',\n",
       " 'chair switch mobile am charger cover',\n",
       " 'amanda any alarm ant']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('filter_text.txt')\n",
    "rdd.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'mango',\n",
       " 'company',\n",
       " 'animal',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'ant',\n",
       " 'mic',\n",
       " 'laptop',\n",
       " 'chair',\n",
       " 'switch',\n",
       " 'mobile',\n",
       " 'am',\n",
       " 'charger',\n",
       " 'cover',\n",
       " 'amanda',\n",
       " 'any',\n",
       " 'alarm',\n",
       " 'ant']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting all the words\n",
    "all_words = rdd.flatMap(lambda x: x.split(' '))\n",
    "all_words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to keep word not starting by a or c\n",
    "def filter_words(x):\n",
    "    \n",
    "    for word in x:\n",
    "        word = str(word)\n",
    "        if (word.startswith('a') or word.startswith('c')):\n",
    "            return False \n",
    "        else:\n",
    "            return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'mango', 'dog', 'mic', 'laptop', 'switch', 'mobile']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_filtered = all_words.filter(filter_words)\n",
    "all_words_filtered.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
